# Adversarial-Robustness-of-Open-source-AI-Models-and-Fine-Tuning-Chains

In this study, Openattack library is used and we have written adversarial_attacks.py file to perform adversarial attack tests and record the results of the attacks. 
experiment_info.py holds the information about the test model and the test dataset.
